{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6afX5qSmiTiu"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yppTMGIBiTiu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from utils.data_utils import (\n",
        "    Mode,\n",
        "    get_features,\n",
        "    get_labels,\n",
        "    get_mixed_trials_data,\n",
        "    normalize_train_labels,\n",
        "    normalize_val_labels,\n",
        ")\n",
        "\n",
        "# Fixed the randomness\n",
        "tf.keras.utils.set_random_seed(33)\n",
        "tf.config.experimental.enable_op_determinism()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PMlEqjUMiTix"
      },
      "source": [
        "## Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMZpZBJDZZcc"
      },
      "outputs": [],
      "source": [
        "N_TRAIN_AGENT = 30000\n",
        "N_VAL_AGENT = 3000\n",
        "NUM_TRIAL = 500\n",
        "\n",
        "train_file = \"train_file.csv\"\n",
        "val_file = \"val_file.csv\"\n",
        "\n",
        "train_data = pd.read_csv(train_file)\n",
        "val_data = pd.read_csv(val_file)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Process data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWoTp-kb2L83"
      },
      "outputs": [],
      "source": [
        "all_train_features = get_features(train_data, N_TRAIN_AGENT, NUM_TRIAL, mode=mode)\n",
        "all_val_features = get_features(val_data, N_VAL_AGENT, NUM_TRIAL, mode=mode)\n",
        "\n",
        "# Padding trials if necessary\n",
        "target_trial = 500\n",
        "all_trials = [target_trial]\n",
        "train_features = get_mixed_trials_data(all_train_features, all_trials, mode=mode)\n",
        "val_features = get_mixed_trials_data(all_val_features, all_trials, mode=mode)\n",
        "\n",
        "# Process labels\n",
        "train_name_to_labels = get_labels(train_data, mode)\n",
        "normalized_train_labels, name_to_scaler = normalize_train_labels(train_name_to_labels)\n",
        "\n",
        "val_name_to_labels = get_labels(val_data, mode)\n",
        "normalized_val_labels = normalize_val_labels(val_name_to_labels, name_to_scaler)\n",
        "\n",
        "print(train_features.shape, len(val_name_to_labels))\n",
        "output_dim = len(val_name_to_labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FCZ7rda6nwcM"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "76fOBwWjP1N7"
      },
      "source": [
        "### GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzK8lMQCzXeV"
      },
      "outputs": [],
      "source": [
        "from utils.hypetune import bayesian_search\n",
        "from model import get_gru_model\n",
        "\n",
        "# (TODO) move to a config file\n",
        "param_grid = {\n",
        "    \"input_x\": train_features.shape[1],\n",
        "    \"input_y\": train_features.shape[2],\n",
        "    \"output_dim\": output_dim,\n",
        "    \"units\": 64 + hp.randint(\"units\", 128),\n",
        "    \"learning_rate\": 3e-4,\n",
        "    \"dropout\": hp.uniform(\"dropout\", 0.15, 0.25),\n",
        "    \"dropout1\": hp.uniform(\"dropout1\", 0.01, 0.1),\n",
        "    \"dropout2\": hp.uniform(\"dropout2\", 0.01, 0.05),\n",
        "    \"epochs\": 25,\n",
        "    \"batch_size\": 256,\n",
        "}\n",
        "\n",
        "best_model, best_params = bayesian_search(\n",
        "    get_gru_model,\n",
        "    param_grid,\n",
        "    train_features,\n",
        "    normalized_train_labels,\n",
        "    val_features,\n",
        "    normalized_val_labels,\n",
        ")\n",
        "\n",
        "print(f\"Found best parameters {best_params}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxAW7DggjOC0"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "callbacks = [EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)]\n",
        "\n",
        "history = best_model.fit(\n",
        "    train_features,\n",
        "    normalized_train_labels,\n",
        "    epochs=200,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=(val_features, normalized_val_labels),\n",
        "    verbose=2,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KPwwDw-API-y"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-gsC8AfzFKf"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv(\"test_file.csv\")\n",
        "all_trials_features = get_features(test_data, num_agents, NUM_TRIAL, mode=mode)\n",
        "test_name_to_labels = get_labels(test_data, mode)\n",
        "normalized_test_labels = normalize_val_labels(test_name_to_labels, name_to_scaler)\n",
        "\n",
        "print(all_test_features.shape, normalized_test_labels.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Predict parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Tbyty4JKOLd"
      },
      "outputs": [],
      "source": [
        "all_prediction = best_model.predict(all_test_features)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot parameter recovery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQ0j02-qe7DN"
      },
      "outputs": [],
      "source": [
        "from utils.data_utils import get_recovered_parameters\n",
        "from utils.plotting import plot_recovery\n",
        "\n",
        "all_test_param = get_recovered_parameters(\n",
        "    name_to_scaler, test_name_to_labels, prediction\n",
        ")\n",
        "plot_recovery(all_test_param, \"alpha\")\n",
        "plot_recovery(all_test_param, \"beta\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
